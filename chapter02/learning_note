*传统的计算机解决问题思路
编写规则，定义“垃圾邮件”，让计算机执行
对于很多问题，规则很难定义
规则在不断变化

*名词
数据的整体叫数据集（data set）
每一行数据成为一个样本
除最后一列，每一列表达样本的一个特征（或称“属性”）
最后一列称为“标记（label）”，或称“结果”
第i个样本行写作X(i),第i个样本的第j个特征写作Xj(i),j为下标，(i)为上标
向量表示为列向量比较多，详见data.PNG
特征空间中可以进行低维空间的思考，再将结果推广到高维空间，详见feature_space.PNG

*机器学习(监督学习)的主要任务：分类和回归
分类主要是二分类，可以解决大部分问题
多分类：1）一些算法只支持完成二分类的任务
        2）但是多分类的任务可以转换成二分类的任务
        3）有一些算法天然解决多分类任务
多标签分类，将一种样本分到多个标签中

*有一些算法只能分别解决回归和分类问题中的一种，但是有一些问题两种问题都可以解决
而且在一些情况下，回归问题可以转换为分类问题

*机器学习的流程中模型可以理解为一个函数f(),详见flow.PNG

*监督学习、非监督学习、半监督学习、强化学习
监督学习：解决分类和回归问题，数据中已给出标签
非监督学习：对没有标记的数据进行分类——聚类分析
            对数据进行降维处理：1）特征提取：扔掉没用的特征；2）特征压缩：PCA:即在尽量少点的损失数据的准确性的情况下将数据进行降维处理，同时也方便进行可视化,详见PCA.PNG
半监督学习：一部分数据有”标记“，另一部分数据没有，通常都先使用无监督学习手段对数据做处理，之后使用监督学习手段做模型的训练和预测
增强学习：一步一更近，详见：RELEARING.PNG

*从另外的角度进行分类
批量学习，在线学习，参数学习，非参数学习
在线学习：及时反映新的环境变化，但是新的数据不一定都好，需要加强对新进数据的监督
参数学习：一定模型（即函数）中有了参数，就可以脱离数据进行预测
非参数学习：不对模型进行过多的假设，但不表示没有参数